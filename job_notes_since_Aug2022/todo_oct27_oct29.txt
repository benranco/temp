

- try DeepBSA with 10 samples and ~ 10000 SNPs
- email DeepBSA team
- send Jun-Jun latest MAF report (split into partitions of less than 1 million)
- send Jun-Jun 20-sample depth files for DeepBSA (all rows with > 4 NAs removed)
- a more careful look at DeepBSA docs
- confirm bug in MAF report generation
- check genotype results from vcf files to report.csv and filled_report.csv
- possibly incorporate new depth stats method (and filled_report?) into pipeline
- see my list of items to improve on the SNPpipeline
- As discussed, please send me the vcf file of count values of all ~2.5 M rows, but including all 36 samples (not only 20 RR1-10 and SS1-10 samples). Please combine the data across 36 samples based on the first four column: chrom, positions, ref, alt. As there are ~2.5 million rows, please split them into three sub cvs files. As you found that some SNP have alt more than one. In these case, those minority alt will be changed as NA (-, as missing data).



In Order:
- create 10 sample ~10000 SNP csv file for DeepBSA (no NAs, no quotes)
- create both 36 sample 20 sample files for DeepBSA (no quotes):
	- all rows
	- without rows which have > 4 NAs
	- no NAs
	- split into sets of < 1000000
- a more careful look at DeepBSA docs
- test DeepBSA with 10 sample file
- email DeepBSA team
- confirm whether there's a difference in both my recent MAF report filtered files and the version I originally sent to Jun-Jun
- send Jun-Jun new 36 sample, 20 sample DeepBSA files, latest MAF report files

- confirm bug in MAF report generation
- check genotype results from vcf files to report.csv and filled_report.csv
- possibly incorporate new depth stats method (and filled_report?) into pipeline
- see my list of items to improve on the SNPpipeline


pay pcfin
buy ointment
john & debbie 10min
anna's web
tithe
rick lanser
cancel amazon prime, channels, samcart
do for jeremy
text dale
donna & nao



mon	3.5 job, buy ointment, sort out streaming, group
tue	3 anna, 4 job
wed	3 anna, 4 job
thu	3 anna, 3.5 job, klap
fri 	luther, 4 job
sat	3 anna, asia

--


sudo mount -t nfs 10.20.0.6:/Public/genomics/junjun/Data-Dec2020/LP-NGS-RawData/LP36-SNPpipeline2022 /work2

Process for my new scripts:
- start with the VCF files generated by freebayes
- extract_from_vcf.sh to create the individual.csv files
- combineVcfResults.R


--
https://github.com/broadinstitute/gatk
https://github.com/broadinstitute/gatk/releases
https://www.biostars.org/p/9498931/       # how to install gatk
https://gatk.broadinstitute.org/hc/en-us/articles/360035531412-HaplotypeCaller-in-a-nutshell
https://gatk.broadinstitute.org/hc/en-us/articles/360037225632-HaplotypeCaller


--


I found a discussion which suggests that maybe FreeBayes can call multiple samples together. Do you think this is what you're talking about?:
https://groups.google.com/g/freebayes/c/3bI3QYGzrsI?pli=1

Explains a process for running freebayes simultaneously on multiple BAM files to create on VCF file, but in parallel on chunks from the reference:
https://bioinformaticsworkbook.org/dataAnalysis/VariantCalling/freebayes-dnaseq-workflow.html#gsc.tab=0
https://github.com/freebayes/freebayes/blob/master/scripts/freebayes-parallel
https://www.biostars.org/p/364221/
very helpful: 
https://groups.google.com/g/freebayes/c/WqSNO8ltD1U


GATK HaplotypeCaller vs Freebayes:
https://www.biostars.org/p/174510/
https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-022-08365-3
https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-015-2059-2
https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-020-03704-1
https://www.biostars.org/p/316574/#365007
https://samtools.github.io/bcftools/howtos/variant-calling.html
https://google.github.io/deepvariant/

sudo yum install parallel


--
Testing freebayes-parallel:

sudo mount -t nfs 10.20.0.6:/Public/genomics/junjun/Data-Dec2020/Fluidigm-May2021 /work3

ls -1 dataTemp/single/*.bam* | head -n 20 > tmp.txt
sed -i 's/^\(.*\)$/cp \1 \.\.\/\.\.\/testFreebayesParallel\/bams/g' tmp.txt
bash tmp.txt


grep -c ^processor /proc/cpuinfo

./freebayes-parallel <(fasta_generate_regions.py ../../../reference/formatted_output.fasta.fai 1000) 26 -f ../../../reference/formatted_output.fasta -L ../../../bamList4.txt >../../../out4.vcf

--

openstack server create \
	--image CentOS7_BenWork7 \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	--flavor mm2.8xlarge \
	benw7

- did a yum upgrade
sudo yum install parallel
sudo mount -t nfs 10.20.0.6:/Public/genomics/junjun/Data-Dec2020/Fluidigm-May2021 /work

- changed the symbolic link for python in /usr/bin to point to python3 rather than python2
- but this broke yum because yum is written in python 2, so, following the advice from sag47 here:  https://www.linuxquestions.org/questions/fedora-35/python3-2-vs-yum-4175419559/
and here:  https://stackoverflow.com/questions/11213520/yum-crashed-with-keyboard-interrupt-error
I did sudo vi /usr/bin/yum
And changed the top line to #!/usr/bin/python2

Following the instructions here to build from source:  https://github.com/vcflib/vcflib#build-from-source
cd vcflib
mkdir -p build && cd build
cmake  -DCMAKE_BUILD_TYPE=Debug -DZIG=OFF -DOPENMP=OFF ..

CMake couldn't find a c++ compiler, so I installed (gcc was already installed with Developer Tools): 
sudo yum install gcc-c++
That worked.

Then, to deal with this: -- Could NOT find pybind11 (missing: pybind11_DIR)
Following recommendation here:  https://stackoverflow.com/questions/61196272/can-someone-explain-the-pybind11-install
Downloaded the last version of pybind11 to support python2.7, version 2.9.2 from: https://github.com/pybind/pybind11/releases
Unzipped it and moved it to this subdirectory of vcflib: external/pybind11-2.9.2
Replaced: 
find_package(pybind11 CONFIG)
with:
add_subdirectory(external/pybind11-2.9.2)

THen, to deal with this: -- Could NOT find BZip2 (missing: BZIP2_LIBRARIES BZIP2_INCLUDE_DIR)
Confirmed the bzip2 was already installed. But according to this: https://askubuntu.com/questions/1071803/why-is-cmake-not-finding-an-installed-package
I need to have the header files available, so:
sudo yum install bzip2-devel

To deal with: --   No package 'htslib' found
sudo yum install htslib
sudo yum install htslib-devel

To deal with: --   No package 'tabixpp' found
Here's the project: https://github.com/vcflib/tabixpp
For now I'll try building vcflb without tabixpp.

To deal with: Pandoc needs to be installed to generate the man pages
sudo yum install pandoc

First attempt to build:
cmake --build .
Had this error: WFAligner.cpp:58:21: error: ‘nullptr’ was not declared in this scope
from:  https://stackoverflow.com/questions/10033373/c-error-nullptr-was-not-declared-in-this-scope-in-eclipse-ide
and:  https://stackoverflow.com/questions/12715005/add-c0x-support-in-cmake
tried: 
set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -std=c++0x")
didn't work, tried: 
set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -std=c++17")
didn't work

This says you need g++ 4.9 or higher:
https://github.com/vcflib/vcflib/issues/243

-----
How about trying to install homebrew and use that to install vcflib: 
https://www.makeuseof.com/install-homebrew-on-linux/

These weren't necessary since I already have them: 
sudo yum group install 'Development Tools'
sudo yum install procps-ng curl file git
sudo yum install libxcrypt-compat

/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
The version of Git that was found does not satisfy requirements for Homebrew.
Please install Git 2.7.0 or newer and add it to your PATH.

Following this guide to install a newer version of git: 
https://computingforgeeks.com/install-git-2-on-centos-7/
sudo yum -y remove git
sudo yum -y remove git-*
sudo yum -y install https://packages.endpointdev.com/rhel/7/os/x86_64/endpoint-repo.x86_64.rpm
sudo yum install git

Back to installing homebrew: 
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
The version of cURL that was found does not satisfy requirements for Homebrew.
Please install cURL 7.41.0 or newer and add it to your PATH.

Followed these instructions to ugrade curl to the latest version: 
https://serverfault.com/questions/321321/upgrade-curl-to-latest-on-centos

Back to installing homebrew: 
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
...got:
==> Checking for `sudo` access (which may request your password)...

We trust you have received the usual lecture from the local System
Administrator. It usually boils down to these three things:

    #1) Respect the privacy of others.
    #2) Think before you type.
    #3) With great power comes great responsibility.

[sudo] password for centos: 
Sorry, try again.

I don't have a sudo password set. So I changed the root password to centos using: 
sudo passwd root. Actually that didn't work.

Found a solution here: 
https://superuser.com/questions/619498/can-i-install-homebrew-without-sudo-privileges
cd software
mkdir homebrew
curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C homebrew
- added ~/software/homebrew/bin to path
- rebooted
brew update-reset
brew update

FINALLY, getting to install vcflif with homebrew: 
brew install brewsci/bio/vcflib

- problems with curl (60) certificate authentication issues

Potential solution: 
https://stackoverflow.com/questions/63289555/cannot-install-anything-with-brew-error-failed-to-download-resource-git-html
https://www.cyberciti.biz/faq/how-to-curl-ignore-ssl-certificate-warnings-command-option/
https://stackoverflow.com/questions/57629010/linuxbrew-curl-certificate-issue
I created ~/.curlrc and pasted this into it: 
insecure
Then I set this environment variable: 
HOMEBREW_CURLRC=1
export HOMEBREW_CURLRC

Then retried:
brew install brewsci/bio/vcflib
Didn't work.

from:  https://stackoverflow.com/questions/36327805/how-to-install-gcc-5-3-with-yum-on-centos-7-2
I tried updating gcc (and gcc-c++): 
sudo yum install centos-release-scl
sudo yum install devtoolset-11-gcc*
scl enable devtoolset-11 bash
which gcc
gcc --version

=============================================================================
=============================================================================

GIVING UP ON TRYING TO USE THE VCFLIB TOOLS. WRITING MY OWN SECOND HALF OF THE SCRIPT TO SORT THE DATA AFTER RUNNING FREEBAYES IN PARALLEL.


grep -c ^processor /proc/cpuinfo
28

tools/freebayes/bin/freebayes -f reference/formatted_output.fasta -p 2 -b bams/MI.M05812_0140.001.TSP0001.160-1-1_R_sorted_markDup.bam -b bams/MI.M05812_0140.001.TSP0008.175-2-6_S_sorted_markDup.bam > test2-twoSamples-sansParallel.vcf

tools/freebayes/bin/freebayes -f reference/formatted_output.fasta -p 2 -L bamList2.txt > test1-twoSamples-sansParallel.vcf
tools/freebayes/bin/freebayes -f reference/formatted_output.fasta -p 2 -L bamList2.txt --regions > test1-twoSamples-sansParallel.vcf

Generate the regions file to run freebayes on multiple regions in parallel:
./fasta_generate_regions.py reference/formatted_output.fasta.fai 1000 > regions_from_fasta.txt

./freebayes-parallel-ben <(cat regions_from_fasta.txt) 26 -f reference/formatted_output.fasta -p 2 -L bamList2.txt > test1-twoSamples.vcf

./freebayes-parallel-ben <(cat regions_from_fasta-noPartitions.txt) 1 -f reference/formatted_output.fasta -p 2 -L bamList2.txt > test1-twoSamples-1cpu-noPartitions.vcf


It seems like even a normal freebayes call is returning the results for only one sample. Possible solution here: 
https://www.biostars.org/p/349213/
"To call variants in a population of samples, each alignment must have a read group identifier attached to it (RG tag), and the header of the BAM file in which it resides must map the RG tags to sample names (SM). Furthermore, read group IDs must be unique across all the files used in the analysis. One read group cannot map to multiple samples. The reason this is required is that freebayes operates on a virtually merged BAM stream provided by the BamTools API. If merging the files in your analysis using bamtools merge would generate a file in which multiple samples map to the same RG, the files are not suitable for use in population calling, and they must be modified."
"Saying this you can of course use bamaddrg as a workaround. But I would recommend to fix your bam file by adding the readgroup with the sample name using samtools addreplacerg or picard AddOrReplaceReadGroups."
(good samtools examples further up in the thread)
Using samtools addreplacerg properly: 
https://www.biostars.org/p/230720/

Added readgroup and sample info to the two samples in bams-few: 

../tools/samtools-1.3.1/samtools addreplacerg -r "ID:TSP0007.175-2-9_R" -r "SM:sampleTSP0007.175-2-9_R" --output-fmt BAM -o MI.M05812_0140.001.TSP0007.175-2-9_R_sorted_markDup-withRG.bam MI.M05812_0140.001.TSP0007.175-2-9_R_sorted_markDup.bam

../tools/samtools-1.3.1/samtools addreplacerg -r "ID:TSP0008.175-2-6_S" -r "SM:sampleTSP0008.175-2-6_S" --output-fmt BAM -o MI.M05812_0140.001.TSP0008.175-2-6_S_sorted_markDup-withRG.bam MI.M05812_0140.001.TSP0008.175-2-6_S_sorted_markDup.bam

Then: 

../tools/samtools-1.3.1/samtools index MI.M05812_0140.001.TSP0007.175-2-9_R_sorted_markDup-withRG.bam

../tools/samtools-1.3.1/samtools index MI.M05812_0140.001.TSP0008.175-2-6_S_sorted_markDup-withRG.bam 

Then:
cd ..
tools/freebayes/bin/freebayes -f reference/formatted_output.fasta -p 2 -b bams-few/MI.M05812_0140.001.TSP0007.175-2-9_R_sorted_markDup-withRG.bam -b bams-few/MI.M05812_0140.001.TSP0008.175-2-6_S_sorted_markDup-withRG.bam > test3-twoSamples-withRG-sansParallel.vcf

Then: 
./freebayes-parallel-ben <(cat regions_from_fasta-noPartitions.txt) 1 -f reference/formatted_output.fasta -p 2 -L bamList2.txt > test3-twoSamples-withRG-1cpu-noPartitions.vcf

Then: 
./freebayes-parallel-ben <(cat regions_from_fasta-1000.txt) 26 -f reference/formatted_output.fasta -p 2 -L bamList2.txt > test3-twoSamples-withRG-26cpu.vcf

Then: 
grep "#CHROM" test3-twoSamples-withRG-sansParallel.vcf > justData_test3-1cpu.vcf 
grep "#CHROM" test3-twoSamples-withRG-sansParallel.vcf > justData_test3-26cpu.vcf 
grep "#CHROM" test3-twoSamples-withRG-sansParallel.vcf > justData_test3-sansParallel.vcf 

grep -E "^[^#]" test3-twoSamples-withRG-sansParallel.vcf >> justData_test3-sansParallel.vcf
grep -E "^[^#]" test3-twoSamples-withRG-1cpu-noPartitions.vcf >> justData_test3-1cpu.vcf
grep -E "^[^#]" test3-twoSamples-withRG-26cpu.vcf >> justData_test3-26cpu.vcf


Then sort the different vcf outputs with: 
mkdir tmp
cat justData_test3-sansParallel.vcf | tools/vcftools/src/perl/vcf-sort -c -t ./tmp > sorted_justData_test3-sansParallel.vcf
cat justData_test3-1cpu.vcf | tools/vcftools/src/perl/vcf-sort -c -t ./tmp > sorted_justData_test3-1cpu.vcf
cat justData_test3-26cpu.vcf | tools/vcftools/src/perl/vcf-sort -c -t ./tmp > sorted_justData_test3-26cpu.vcf

After editing my own custom freebayes-parallel-ben script:
./freebayes-parallel-ben <(cat regions_from_fasta-1000.txt) 26 -f reference/formatted_output.fasta -p 2 -L bamList2.txt > zzz.vcf
./freebayes-parallel-ben <(cat regions_from_fasta-1000.txt) 26 -f reference/formatted_output.fasta -p 2 -L bamList10.txt > zzz.vcf

About this error: 
parallel: Warning: No more file handles. 
parallel: Warning: Raising ulimit -n or /etc/security/limits.conf may help.
https://unix.stackexchange.com/questions/624952/parallel-warning-no-more-file-handles


I also created the add_samplenames_to_bams.sh script. After testing I began running it on the bam files from the three LP36 pipelines.

For each pipeline: 
./add_samplenames_to_bams-pipe1.sh
Then check one of the samples to make sure it has the proper sample name and readgroup: 
../tools/samtools-1.3.1/samtools view -H RS10_filtered_sorted_markDup_withSN_pipe1.bam | tail
ls bamsWithSNs_pipe1/*.bam > pipe1_bamlist.txt
./fasta_generate_regions.py reference/formatted_output.fasta.fai 100000 > pipe1_regions.txt
nohup ./freebayes-parallel-ben <(cat pipe1_regions.txt) 26 -f reference/formatted_output.fasta -p 2 -L pipe1_bamlist.txt > LP36_pipe1.vcf &

nohup ./freebayes-parallel-ben <(cat pipe2_regions.txt) 26 -f reference/formatted_output.fasta -p 2 -L pipe2_bamlist.txt > LP36_pipe2.vcf &

nohup ./freebayes-parallel-ben <(cat pipe3_regions.txt) 26 -f reference/formatted_output.fasta -p 2 -L pipe3_bamlist.txt > LP36_pipe3.vcf &


sudo mount -t nfs 10.20.0.6:/Public/genomics/junjun/Data-Dec2020/LP-NGS-RawData/LP36-SNPpipeline2022 /work2

sudo mount -t nfs 10.20.0.6:/Public/genomics/junjun/Data-Dec2020/LP-NGS-RawData/LP36-SNPpipeline2022/bamsWithSNs/pipe1 /work2



openstack server create \
	--image CentOS7_BenWork7 \
  --security-group default \
	--key-name brancourt \
	--nic net-id=Private \
	--flavor mm2.8xlarge \
	ben3

- did a yum upgrade
sudo yum install parallel


--
Hi Jun-Jun,

I've finished testing my scripts to run freebayes in parallel, and I'm ready to begin running it on the LP36 BAM files. I had to add sample names and read groups to the existing BAM files for the LP36 dataset, because freebayes requires these to operate on more than one sample at a time. For the sample names, I used, for example, "RS1", "SS1", "SN1", "C1", and for the read groups I just assigned a single read group to all the reads in a file, for example "readGroup_RS1".

Would you like me to run freebayes on all 36 samples, or just a subset?


Ben










===================================



[centos@bentest scripts]$ ./freebayes-parallel 
usage: ./freebayes-parallel [regions file] [ncpus] [freebayes arguments]

Run freebayes in parallel over regions listed in regions file, using ncpus processors.
Will merge and sort output, producing a uniform VCF stream on stdout.  Flags to freebayes
which would write to e.g. a particular file will obviously cause problms, so caution is
encouraged when using this script.

examples:

Run freebayes in parallel on 100000bp chunks of the ref (fasta_generate_regions.py is also
located in the scripts/ directory in the freebayes distribution).  Use 36 threads.

    freebayes-parallel <(fasta_generate_regions.py ref.fa.fai 100000) 36 -f ref.fa aln.bam >out.vcf

Generate regions that are equal in terms of data content, and thus have lower variance
in runtime.  This will yield better resource utilization.

    bamtools coverage -in aln.bam | coverage_to_regions.py ref.fa 500 >ref.fa.500.regions
    freebayes-parallel ref.fa.500.regions 36 -f ref.fa aln.bam >out.vcf

[centos@bentest scripts]$ 

=========================

./fasta_generate_regions.py 
usage:  ./fasta_generate_regions.py  <fasta file or index file> <region size>
generates a list of freebayes/bamtools region specifiers on stdout
intended for use in creating cluster jobs

=========================

/coverage_to_regions.py 
usage: <bamtools_coverage_output  ./coverage_to_regions.py  fasta_index num_regions >regions.bed
Generates regions with even sequencing coverage, provided an input of coverage per-position as
generated by bamtools coverage.  In other words, generates regions such that the integral of
coverage is approximately equal for each.  These can be used when variant calling to reduce
variance in job runtime.

=========================









======================================================================
====================================================================

-- The C compiler identification is GNU 4.8.5
-- The CXX compiler identification is GNU 4.8.5
-- Check for working C compiler: /usr/bin/cc
-- Check for working C compiler: /usr/bin/cc - works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /usr/bin/c++
-- Check for working CXX compiler: /usr/bin/c++ - works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found PkgConfig: /usr/bin/pkg-config (found version "0.27.1") 
-- Could NOT find pybind11 (missing: pybind11_DIR)
-- Found BZip2: /usr/lib64/libbz2.so (found version "1.0.6") 
-- Looking for BZ2_bzCompressInit
-- Looking for BZ2_bzCompressInit - found
-- Looking for lzma_auto_decoder in /usr/lib64/liblzma.so
-- Looking for lzma_auto_decoder in /usr/lib64/liblzma.so - found
-- Looking for lzma_easy_encoder in /usr/lib64/liblzma.so
-- Looking for lzma_easy_encoder in /usr/lib64/liblzma.so - found
-- Looking for lzma_lzma_preset in /usr/lib64/liblzma.so
-- Looking for lzma_lzma_preset in /usr/lib64/liblzma.so - found
-- Found LibLZMA: /usr/lib64/liblzma.so (found version "5.2.2") 
-- Found ZLIB: /usr/lib64/libz.so (found version "1.2.7") 
-- Found CURL: /usr/lib64/libcurl.so (found version "7.29.0")  
-- 

-- Looking for pthread.h
-- Looking for pthread.h - found
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Checking for module 'htslib'
--   No package 'htslib' found
-- Checking for module 'tabixpp'
--   No package 'tabixpp' found
-- /work3/testFreebayesParallel/vcflib/contrib/WFA2-lib/lib/libwfacpp.a
CMake Error at CMakeLists.txt:474 (pybind11_add_module):
  Unknown CMake command "pybind11_add_module".


-- Configuring incomplete, errors occurred!
See also "/work3/testFreebayesParallel/vcflib/build/CMakeFiles/CMakeOutput.log".
See also "/work3/testFreebayesParallel/vcflib/build/CMakeFiles/CMakeError.log".


==========

https://stackoverflow.com/questions/61196272/can-someone-explain-the-pybind11-install




